{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2604e4fa",
   "metadata": {},
   "source": [
    "### Task: 0\n",
    "Build an N-gram language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c54610fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram model (sample):\n",
      "('alice',) -> {'was': 1, 'without': 1}\n",
      "('was',) -> {'beginning': 1, 'reading': 1}\n",
      "('beginning',) -> {'to': 1}\n",
      "('to',) -> {'get': 1, 'do': 1}\n",
      "('get',) -> {'very': 1}\n",
      "\n",
      "Trigram model (sample):\n",
      "('alice', 'was') -> {'beginning': 1}\n",
      "('was', 'beginning') -> {'to': 1}\n",
      "('beginning', 'to') -> {'get': 1}\n",
      "('to', 'get') -> {'very': 1}\n",
      "('get', 'very') -> {'tired': 1}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "corpus = \"\"\"\n",
    "Alice was beginning to get very tired of sitting by her sister on the bank,\n",
    "and of having nothing to do. Once or twice she had peeped into the book her sister was reading,\n",
    "but it had no pictures or conversations in it, and what is the use of a book, thought Alice without pictures or conversations?\n",
    "\"\"\"\n",
    "\n",
    "tokens = nltk.word_tokenize(corpus.lower())\n",
    "\n",
    "def build_ngram(tokens, n):\n",
    "    model = defaultdict(Counter)\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        context = tuple(tokens[i:i+n-1])\n",
    "        next_word = tokens[i+n-1]\n",
    "        model[context][next_word] += 1\n",
    "    return model\n",
    "\n",
    "bigram_model = build_ngram(tokens, 2)\n",
    "trigram_model = build_ngram(tokens, 3)\n",
    "\n",
    "print(\"Bigram model (sample):\")\n",
    "for ctx, cnt in list(bigram_model.items())[:5]:\n",
    "    print(f\"{ctx} -> {dict(cnt)}\")\n",
    "\n",
    "print(\"\\nTrigram model (sample):\")\n",
    "for ctx, cnt in list(trigram_model.items())[:5]:\n",
    "    print(f\"{ctx} -> {dict(cnt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b658fa",
   "metadata": {},
   "source": [
    "### Task 1:\n",
    "Compare bi- and tri-gram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73a29e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bigram prediction for 'alice': was\n",
      "Trigram prediction for 'alice was': beginning\n"
     ]
    }
   ],
   "source": [
    "def predict_next(model, context):\n",
    "    if context in model:\n",
    "        return model[context].most_common(1)[0][0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "context_bigram = (\"alice\",)\n",
    "context_trigram = (\"alice\", \"was\")\n",
    "\n",
    "print(\"\\nBigram prediction for 'alice':\", predict_next(bigram_model, context_bigram))\n",
    "print(\"Trigram prediction for 'alice was':\", predict_next(trigram_model, context_trigram))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b90f22",
   "metadata": {},
   "source": [
    "### Task 2:\n",
    "Apply interpolation/backoff to your model so that it can better handle unknown words/prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ccce53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Backoff prediction for 'tired of': sitting\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def backoff_predict(context):\n",
    "    if len(context) == 2 and context in trigram_model:\n",
    "        return trigram_model[context].most_common(1)[0][0]\n",
    "    elif len(context) >= 1 and context[-1:] in bigram_model:\n",
    "        return bigram_model[context[-1:]].most_common(1)[0][0]\n",
    "    else:\n",
    "        return random.choice(tokens)\n",
    "\n",
    "# Example with missing context\n",
    "context_example = (\"tired\", \"of\")\n",
    "print(\"\\nBackoff prediction for 'tired of':\", backoff_predict(context_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc51ea5",
   "metadata": {},
   "source": [
    "### Task 3: Generate a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b52a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated sentence:\n",
      "alice was beginning to get very tired of sitting by her sister\n"
     ]
    }
   ],
   "source": [
    "def generate_sentence(prompt, length=10):\n",
    "    generated = list(prompt)\n",
    "    for _ in range(length):\n",
    "        ctx = tuple(generated[-2:]) if len(generated) >= 2 else tuple(generated[-1:])\n",
    "        next_word = backoff_predict(ctx)\n",
    "        generated.append(next_word)\n",
    "    return \" \".join(generated)\n",
    "\n",
    "prompt = [\"alice\", \"was\"]\n",
    "generated_sentence = generate_sentence(prompt, length=10)\n",
    "print(\"\\nGenerated sentence:\")\n",
    "print(generated_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
